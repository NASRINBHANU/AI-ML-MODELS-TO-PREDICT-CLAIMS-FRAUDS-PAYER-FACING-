# -*- coding: utf-8 -*-
"""Final COLAB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UJYTg2G5rEVPaPxMtBByqsripKGheFaP
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd 
import datetime as dt
import numpy as np
import matplotlib.pyplot as  plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import xgboost as xgb
# %matplotlib inline
sns.set(style='whitegrid', palette='muted', font_scale=1.5)

RANDOM_SEED = 42
pd.set_option('display.max_columns', None)

fraud_data=pd.read_csv("/content/Fraud_data.csv")
In_pat=pd.read_csv("/content/Inpatientdata.csv")
Out_pat=pd.read_csv("/content/Outpatientdata.csv")
Beneficiary=pd.read_csv("/content/Beneficiarydata.csv")

fraud_data.info()

In_pat.info()

Out_pat.info(max_cols=None)

Beneficiary.info()

Beneficiary.isna().sum()

##Replacing 2 with 0 for chronic conditions, and renal to 0 and 1 
Beneficiary = Beneficiary.replace({'ChronicCond_Alzheimer': 2, 'ChronicCond_Heartfailure': 2, 'ChronicCond_KidneyDisease': 2,
                           'ChronicCond_Cancer': 2, 'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2, 
                           'ChronicCond_Diabetes': 2, 'ChronicCond_IschemicHeart': 2, 'ChronicCond_Osteoporasis': 2, 
                           'ChronicCond_rheumatoidarthritis': 2, 'ChronicCond_stroke': 2 }, 0)

Beneficiary = Beneficiary.replace({'RenalDiseaseIndicator': 'Y'}, 1)

Beneficiary.head(10)

##Add Age of Person based on his/her DOD(Date of death ) and DOB (Date of Birth)
Beneficiary['DOB'] = pd.to_datetime(Beneficiary['DOB'] , format = '%Y-%m-%d')
Beneficiary['DOD'] = pd.to_datetime(Beneficiary['DOD'],format = '%Y-%m-%d',errors='ignore')
Beneficiary['Age'] = round(((Beneficiary['DOD'] - Beneficiary['DOB']).dt.days)/365)

Beneficiary.head(10)

##Calculate age based on 2009-12-01
Beneficiary.Age.fillna(round(((pd.to_datetime('2009-12-01' , format = '%Y-%m-%d') - Beneficiary['DOB']).dt.days)/365),inplace=True)

Beneficiary.head(10)

##wheather dead
Beneficiary.loc[Beneficiary.DOD.isna(),'WhetherDead']=0
Beneficiary.loc[Beneficiary.DOD.notna(),'WhetherDead']=1

Beneficiary.head(10)

plt.title("Potential Fraud Test distribution")
fraud_data.groupby( ["PotentialFraud"] ).Provider.count().plot(kind = "bar", figsize = (10,6))
plt.xlabel('Potential Fraud Class ')
plt.ylabel('Count')
plt.show()

fraud_data.groupby( ["PotentialFraud"] ).Provider.count()

df=pd.concat([In_pat,Out_pat])
df=pd.merge(df,fraud_data,on="Provider",how="outer")
df=df.fillna(0)

df.head(50)

#Label categorical data
from sklearn import preprocessing
catcols = ['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',
        'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'AdmissionDt', 'ClmAdmitDiagnosisCode',
       'DischargeDt', 'DiagnosisGroupCode',
       'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',
       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',
       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',
       'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',
       'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',
       'ClmProcedureCode_6']

le = {}
X = df[catcols].astype(str)
for i in catcols:
    print(i)
    le[i] = preprocessing.LabelEncoder()
    le[i].fit(X[i].astype(str))
    df[i] = le[i].transform(df[i].astype(str))

df.info()

##prepare data
cols = ['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',
       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'AdmissionDt', 'ClmAdmitDiagnosisCode',
       'DeductibleAmtPaid', 'DischargeDt', 'DiagnosisGroupCode',
       'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',
       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',
       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',
       'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',
       'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',
       'ClmProcedureCode_6']

X = df[cols]
Y = df["PotentialFraud"].apply(lambda x: True if x == "Yes" else False)

Y

## Split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=12)

clf = xgb.XGBClassifier(n_jobs=12, n_estimators=500)
clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)],
        eval_metric=["auc","error","logloss"],
        verbose=10)

from xgboost import plot_importance
plot_importance(clf)

from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from matplotlib import pyplot

xgb_probs=clf.predict_proba(X_test)
ns_probs = [0 for _ in range(len(y_test))]
ns_auc=roc_auc_score(y_test,ns_probs)

xgb_probs

xgb_probs=xgb_probs[:,1]

xgb_probs

xgb_auc=roc_auc_score(y_test,xgb_probs)

print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('XGB: ROC AUC=%.3f' % (xgb_auc))

ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_probs)

pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(xgb_fpr, xgb_tpr, marker='.', label='xgb')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()

cols = ['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt',
       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'AdmissionDt', 'ClmAdmitDiagnosisCode',
       'DeductibleAmtPaid', 'DischargeDt', 'DiagnosisGroupCode',
       'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',
       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',
       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',
       'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',
       'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',
       'ClmProcedureCode_6']

X = df[cols]
Y = df["PotentialFraud"].apply(lambda x: True if x == "Yes" else False)

Y

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=42)

clf = xgb.XGBClassifier(n_jobs=12, n_estimators=500)
clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)],
        eval_metric=["auc","error","logloss"],
        verbose=10)

plot_importance(clf)

xgb_probs=clf.predict_proba(X_test)
ns_probs = [0 for _ in range(len(y_test))]
ns_auc=roc_auc_score(y_test,ns_probs)
xgb_probs=xgb_probs[:,1]
xgb_auc=roc_auc_score(y_test,xgb_probs)
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('XGB: ROC AUC=%.3f' % (xgb_auc))
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_probs)

pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(xgb_fpr, xgb_tpr, marker='.', label='xgb')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()

##add beneficiary info and improve In pat abd out pat combine
In_pat['AdmissionDt'] = pd.to_datetime(In_pat['AdmissionDt'] , format = '%Y-%m-%d')
In_pat['DischargeDt'] = pd.to_datetime(In_pat['DischargeDt'] , format = '%Y-%m-%d')
In_pat['AdmitForDays'] = ((In_pat['DischargeDt'] - In_pat['AdmissionDt']).dt.days)+1

print(Out_pat.columns)

df1=pd.merge(Out_pat,In_pat,
                              left_on=['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',
       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2',
       'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5',
       'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8',
       'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1',
       'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4',
       'ClmProcedureCode_5', 'ClmProcedureCode_6', 'DeductibleAmtPaid',
       'ClmAdmitDiagnosisCode'],
                              right_on=['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',
       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2',
       'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5',
       'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8',
       'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1',
       'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4',
       'ClmProcedureCode_5', 'ClmProcedureCode_6', 'DeductibleAmtPaid',
       'ClmAdmitDiagnosisCode']
                              ,how='outer')

df1.shape

df1=pd.merge(df1,Beneficiary,left_on='BeneID',right_on='BeneID',how='inner')

df1.shape

df1=pd.merge(df1,fraud_data,on="Provider",how="outer")

df1.isnull().sum()*100/len(df1)

import seaborn as sns
sns.set_style('white',rc={'figure.figsize':(12,8)})
LABELS = ["Non Fraud", "Fraud"]
pd.value_counts(df1['PotentialFraud'], sort = True).plot(kind='bar',rot=0,figsize = (10,6))
plt.title("Potential Fraud distribution in Aggregated claim transactional data")
plt.xticks(range(2), LABELS)
plt.xlabel("Potential Fraud Class ")
plt.ylabel("Number of PotentialFraud per Class ")

##race
race_count=pd.value_counts(Beneficiary['Race'],sort=True)
(race_count*100/len(Beneficiary)).plot(kind = 'bar', rot=0,figsize=(16,8),fontsize=12,legend=True)
plt.show()

#states
states_count=pd.value_counts(Beneficiary['State'],sort=True)
(states_count*100/len(Beneficiary)).plot(kind = 'bar', rot=0,figsize=(16,8),fontsize=12,legend=True)
plt.show()

##top procedures
sns.set(rc={'figure.figsize':(12,8)},style='white')
ax=sns.countplot(x='ClmProcedureCode_1',hue='PotentialFraud',data=df1
              ,order=df1.ClmProcedureCode_1.value_counts().iloc[:10].index)

plt.title('Top-10 Procedures in Fraud')
    
plt.show()

## top physicians


ax= sns.countplot(x='AttendingPhysician',hue='PotentialFraud',data=df1
              ,order=df1.AttendingPhysician.value_counts().iloc[:15].index)

    
plt.title('Top-15 physicians ')
plt.xticks(rotation=90)
plt.show()

##create numeric average columns by provider
df1["PerProviderAvg_InscClaimAmtReimbursed"]=df1.groupby('Provider')['InscClaimAmtReimbursed'].transform('mean')
df1["PerProviderAvg_DeductibleAmtPaid"]=df1.groupby('Provider')['DeductibleAmtPaid'].transform('mean')
df1["PerProviderAvg_IPAnnualReimbursementAmt"]=df1.groupby('Provider')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerProviderAvg_IPAnnualDeductibleAmt"]=df1.groupby('Provider')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerProviderAvg_OPAnnualReimbursementAmt"]=df1.groupby('Provider')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerProviderAvg_OPAnnualDeductibleAmt"]=df1.groupby('Provider')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerProviderAvg_Age"]=df1.groupby('Provider')['Age'].transform('mean')
df1["PerProviderAvg_NoOfMonths_PartACov"]=df1.groupby('Provider')['NoOfMonths_PartACov'].transform('mean')
df1["PerProviderAvg_NoOfMonths_PartBCov"]=df1.groupby('Provider')['NoOfMonths_PartBCov'].transform('mean')
df1["PerProviderAvg_AdmitForDays"]=df1.groupby('Provider')['AdmitForDays'].transform('mean')

df1

##create numeric average columns by BENEId
df1["PerBeneIDAvg_InscClaimAmtReimbursed"]=df1.groupby('BeneID')['InscClaimAmtReimbursed'].transform('mean')
df1["PerBeneIDAvg_DeductibleAmtPaid"]=df1.groupby('BeneID')['DeductibleAmtPaid'].transform('mean')
df1["PerBeneIDAvg_IPAnnualReimbursementAmt"]=df1.groupby('BeneID')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerBeneIDAvg_IPAnnualDeductibleAmt"]=df1.groupby('BeneID')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerBeneIDAvg_OPAnnualReimbursementAmt"]=df1.groupby('BeneID')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerBeneIDAvg_OPAnnualDeductibleAmt"]=df1.groupby('BeneID')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerBeneIDAvg_AdmitForDays"]=df1.groupby('BeneID')['AdmitForDays'].transform('mean')

df1

##create numeric average columns by physician
df1["PerOperatingPhysicianAvg_InscClaimAmtReimbursed"]=df1.groupby('OperatingPhysician')['InscClaimAmtReimbursed'].transform('mean')
df1["PerOperatingPhysicianAvg_DeductibleAmtPaid"]=df1.groupby('OperatingPhysician')['DeductibleAmtPaid'].transform('mean')
df1["PerOperatingPhysicianAvg_IPAnnualReimbursementAmt"]=df1.groupby('OperatingPhysician')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerOperatingPhysicianAvg_IPAnnualDeductibleAmt"]=df1.groupby('OperatingPhysician')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerOperatingPhysicianAvg_OPAnnualReimbursementAmt"]=df1.groupby('OperatingPhysician')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerOperatingPhysicianAvg_OPAnnualDeductibleAmt"]=df1.groupby('OperatingPhysician')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerOperatingPhysicianAvg_AdmitForDays"]=df1.groupby('OperatingPhysician')['AdmitForDays'].transform('mean')

df1

##create numeric average columns by DiagnosisGroupCode
df1["PerDiagnosisGroupCodeAvg_InscClaimAmtReimbursed"]=df1.groupby('DiagnosisGroupCode')['InscClaimAmtReimbursed'].transform('mean')
df1["PerDiagnosisGroupCodeAvg_DeductibleAmtPaid"]=df1.groupby('DiagnosisGroupCode')['DeductibleAmtPaid'].transform('mean')
df1["PerDiagnosisGroupCodeAvg_IPAnnualReimbursementAmt"]=df1.groupby('DiagnosisGroupCode')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerDiagnosisGroupCodeAvg_IPAnnualDeductibleAmt"]=df1.groupby('DiagnosisGroupCode')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerDiagnosisGroupCodeAvg_OPAnnualReimbursementAmt"]=df1.groupby('DiagnosisGroupCode')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerDiagnosisGroupCodeAvg_OPAnnualDeductibleAmt"]=df1.groupby('DiagnosisGroupCode')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerDiagnosisGroupCodeAvg_AdmitForDays"]=df1.groupby('DiagnosisGroupCode')['AdmitForDays'].transform('mean')

##create numeric average columns by ClmAdmitDiagnosisCode
df1["PerClmAdmitDiagnosisCodeAvg_InscClaimAmtReimbursed"]=df1.groupby('ClmAdmitDiagnosisCode')['InscClaimAmtReimbursed'].transform('mean')
df1["PerClmAdmitDiagnosisCodeAvg_DeductibleAmtPaid"]=df1.groupby('ClmAdmitDiagnosisCode')['DeductibleAmtPaid'].transform('mean')
df1["PerClmAdmitDiagnosisCodeAvg_IPAnnualReimbursementAmt"]=df1.groupby('ClmAdmitDiagnosisCode')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerClmAdmitDiagnosisCodeAvg_IPAnnualDeductibleAmt"]=df1.groupby('ClmAdmitDiagnosisCode')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerClmAdmitDiagnosisCodeAvg_OPAnnualReimbursementAmt"]=df1.groupby('ClmAdmitDiagnosisCode')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerClmAdmitDiagnosisCodeAvg_OPAnnualDeductibleAmt"]=df1.groupby('ClmAdmitDiagnosisCode')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerClmAdmitDiagnosisCodeAvg_AdmitForDays"]=df1.groupby('ClmAdmitDiagnosisCode')['AdmitForDays'].transform('mean')

df1.info()

df1["PerClmDiagnosisCode_1Avg_InscClaimAmtReimbursed"]=df1.groupby('ClmDiagnosisCode_1')['InscClaimAmtReimbursed'].transform('mean')
df1["PerClmDiagnosisCode_1Avg_DeductibleAmtPaid"]=df1.groupby('ClmDiagnosisCode_1')['DeductibleAmtPaid'].transform('mean')
df1["PerClmDiagnosisCode_1Avg_IPAnnualReimbursementAmt"]=df1.groupby('ClmDiagnosisCode_1')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerClmDiagnosisCode_1Avg_IPAnnualDeductibleAmt"]=df1.groupby('ClmDiagnosisCode_1')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerClmDiagnosisCode_1Avg_OPAnnualReimbursementAmt"]=df1.groupby('ClmDiagnosisCode_1')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerClmDiagnosisCode_1Avg_OPAnnualDeductibleAmt"]=df1.groupby('ClmDiagnosisCode_1')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerClmDiagnosisCode_1Avg_AdmitForDays"]=df1.groupby('ClmDiagnosisCode_1')['AdmitForDays'].transform('mean')

df1["PerClmDiagnosisCode_2Avg_InscClaimAmtReimbursed"]=df1.groupby('ClmDiagnosisCode_2')['InscClaimAmtReimbursed'].transform('mean')
df1["PerClmDiagnosisCode_2Avg_DeductibleAmtPaid"]=df1.groupby('ClmDiagnosisCode_2')['DeductibleAmtPaid'].transform('mean')
df1["PerClmDiagnosisCode_2Avg_IPAnnualReimbursementAmt"]=df1.groupby('ClmDiagnosisCode_2')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerClmDiagnosisCode_2Avg_IPAnnualDeductibleAmt"]=df1.groupby('ClmDiagnosisCode_2')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerClmDiagnosisCode_2Avg_OPAnnualReimbursementAmt"]=df1.groupby('ClmDiagnosisCode_2')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerClmDiagnosisCode_2Avg_OPAnnualDeductibleAmt"]=df1.groupby('ClmDiagnosisCode_2')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerClmDiagnosisCode_2Avg_AdmitForDays"]=df1.groupby('ClmDiagnosisCode_2')['AdmitForDays'].transform('mean')

df1["PerClmDiagnosisCode_3Avg_InscClaimAmtReimbursed"]=df1.groupby('ClmDiagnosisCode_3')['InscClaimAmtReimbursed'].transform('mean')
df1["PerClmDiagnosisCode_3Avg_DeductibleAmtPaid"]=df1.groupby('ClmDiagnosisCode_3')['DeductibleAmtPaid'].transform('mean')
df1["PerClmDiagnosisCode_3Avg_IPAnnualReimbursementAmt"]=df1.groupby('ClmDiagnosisCode_3')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerClmDiagnosisCode_3Avg_IPAnnualDeductibleAmt"]=df1.groupby('ClmDiagnosisCode_3')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerClmDiagnosisCode_3Avg_OPAnnualReimbursementAmt"]=df1.groupby('ClmDiagnosisCode_3')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerClmDiagnosisCode_3Avg_OPAnnualDeductibleAmt"]=df1.groupby('ClmDiagnosisCode_3')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerClmDiagnosisCode_3Avg_AdmitForDays"]=df1.groupby('ClmDiagnosisCode_3')['AdmitForDays'].transform('mean')

df1["PerClmDiagnosisCode_4Avg_InscClaimAmtReimbursed"]=df1.groupby('ClmDiagnosisCode_4')['InscClaimAmtReimbursed'].transform('mean')
df1["PerClmDiagnosisCode_4Avg_DeductibleAmtPaid"]=df1.groupby('ClmDiagnosisCode_4')['DeductibleAmtPaid'].transform('mean')
df1["PerClmDiagnosisCode_4Avg_IPAnnualReimbursementAmt"]=df1.groupby('ClmDiagnosisCode_4')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerClmDiagnosisCode_4Avg_IPAnnualDeductibleAmt"]=df1.groupby('ClmDiagnosisCode_4')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerClmDiagnosisCode_4Avg_OPAnnualReimbursementAmt"]=df1.groupby('ClmDiagnosisCode_4')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerClmDiagnosisCode_4Avg_OPAnnualDeductibleAmt"]=df1.groupby('ClmDiagnosisCode_4')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerClmDiagnosisCode_4Avg_AdmitForDays"]=df1.groupby('ClmDiagnosisCode_4')['AdmitForDays'].transform('mean')

df1["PerClmProcedureCode_1Avg_InscClaimAmtReimbursed"]=df1.groupby('ClmProcedureCode_1')['InscClaimAmtReimbursed'].transform('mean')
df1["PerClmProcedureCode_1Avg_DeductibleAmtPaid"]=df1.groupby('ClmProcedureCode_1')['DeductibleAmtPaid'].transform('mean')
df1["PerClmProcedureCode_1Avg_IPAnnualReimbursementAmt"]=df1.groupby('ClmProcedureCode_1')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerClmProcedureCode_1Avg_IPAnnualDeductibleAmt"]=df1.groupby('ClmProcedureCode_1')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerClmProcedureCode_1Avg_OPAnnualReimbursementAmt"]=df1.groupby('ClmProcedureCode_1')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerClmProcedureCode_1Avg_OPAnnualDeductibleAmt"]=df1.groupby('ClmProcedureCode_1')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerClmProcedureCode_1Avg_AdmitForDays"]=df1.groupby('ClmProcedureCode_1')['AdmitForDays'].transform('mean')

df1["PerClmProcedureCode_2Avg_InscClaimAmtReimbursed"]=df1.groupby('ClmProcedureCode_2')['InscClaimAmtReimbursed'].transform('mean')
df1["PerClmProcedureCode_2Avg_DeductibleAmtPaid"]=df1.groupby('ClmProcedureCode_2')['DeductibleAmtPaid'].transform('mean')
df1["PerClmProcedureCode_2Avg_IPAnnualReimbursementAmt"]=df1.groupby('ClmProcedureCode_2')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerClmProcedureCode_2Avg_IPAnnualDeductibleAmt"]=df1.groupby('ClmProcedureCode_2')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerClmProcedureCode_2Avg_OPAnnualReimbursementAmt"]=df1.groupby('ClmProcedureCode_2')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerClmProcedureCode_2Avg_OPAnnualDeductibleAmt"]=df1.groupby('ClmProcedureCode_2')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerClmProcedureCode_2Avg_AdmitForDays"]=df1.groupby('ClmProcedureCode_2')['AdmitForDays'].transform('mean')

df1["PerClmProcedureCode_3Avg_InscClaimAmtReimbursed"]=df1.groupby('ClmProcedureCode_3')['InscClaimAmtReimbursed'].transform('mean')
df1["PerClmProcedureCode_3Avg_DeductibleAmtPaid"]=df1.groupby('ClmProcedureCode_3')['DeductibleAmtPaid'].transform('mean')
df1["PerClmProcedureCode_3Avg_IPAnnualReimbursementAmt"]=df1.groupby('ClmProcedureCode_3')['IPAnnualReimbursementAmt'].transform('mean')
df1["PerClmProcedureCode_3Avg_IPAnnualDeductibleAmt"]=df1.groupby('ClmProcedureCode_3')['IPAnnualDeductibleAmt'].transform('mean')
df1["PerClmProcedureCode_3Avg_OPAnnualReimbursementAmt"]=df1.groupby('ClmProcedureCode_3')['OPAnnualReimbursementAmt'].transform('mean')
df1["PerClmProcedureCode_3Avg_OPAnnualDeductibleAmt"]=df1.groupby('ClmProcedureCode_3')['OPAnnualDeductibleAmt'].transform('mean')
df1["PerClmProcedureCode_3Avg_AdmitForDays"]=df1.groupby('ClmProcedureCode_3')['AdmitForDays'].transform('mean')

df1["PerClmProcedureCode_3Avg_InscClaimAmtReimbursed"].isnull().sum()

df1.shape

df1

##replace all null by 0
num_cols=df1.select_dtypes([np.number]).columns


df1[num_cols]=df1[num_cols].fillna(value=0)

df1

df1.isnull().sum()

##select features
cols=df1.columns
cols[:58]

remove_columns=['BeneID', 'ClaimID', 'ClaimStartDt','ClaimEndDt','AttendingPhysician',
       'OperatingPhysician', 'OtherPhysician', 'ClmDiagnosisCode_1',
       'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4',
       'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7',
       'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10',
       'ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3',
       'ClmProcedureCode_4', 'ClmProcedureCode_5', 'ClmProcedureCode_6',
       'ClmAdmitDiagnosisCode', 'AdmissionDt',
       'DischargeDt', 'DiagnosisGroupCode','DOB', 'DOD',
        'State', 'County']
df1=df1.drop(axis=1,columns=remove_columns)

df1.info()

df1

df1.info(verbose=True)

df1.Gender=df1.Gender.astype('category')
df1.Race=df1.Race.astype('category')

df1=pd.get_dummies(df1,columns=['Gender','Race'],drop_first=True)

df1

df1.replace(['Yes','No'],['1','0'],inplace=True)
df1['PotentialFraud']=df1.PotentialFraud.astype('int64')

##aggregation for each provider
df1=df1.groupby(['Provider','PotentialFraud'],as_index=False).agg('sum')
df1

df1.info(verbose=True)

X=df1.drop(axis=1,columns=['Provider','PotentialFraud'])
Y=df1['PotentialFraud']

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=12)

print(X_train.shape)
print(y_train.shape)

##logistic

from sklearn.linear_model import LogisticRegressionCV

logic=LogisticRegressionCV(cv=10,class_weight='balanced',random_state=111)
logic.fit(X_train,y_train)

logic_probs=logic.predict_proba(X_test)
ns_probs = [0 for _ in range(len(y_test))]
ns_auc=roc_auc_score(y_test,ns_probs)
logic_probs=logic_probs[:,1]
logic_auc=roc_auc_score(y_test,logic_probs)
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('logic: ROC AUC=%.3f' % (logic_auc))
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
logic_fpr, logic_tpr, _ = roc_curve(y_test, logic_probs)


pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(logic_fpr, logic_tpr, marker='.', label='logic')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()

fig = plt.figure(figsize=(12,8))

sns.distplot(logic_tpr,color='firebrick')

sns.distplot(logic_fpr,color='darkblue')
plt.title('TPR Vs FPR ')
plt.xlim([-.25, 1.2])

plt.text(0.1,4,'Negatives',color='darkblue')
plt.text(0.7,4,'Positives',color='firebrick')
plt.xlabel('Probability')
plt.ylabel('Distribution')
plt.show()

log_train_pred_60=(logic.predict_proba(X_train)[:,1]>0.60).astype(bool)
log_val_pred_60=(logic.predict_proba(X_test)[:,1]>0.60).astype(bool)

from sklearn.metrics import cohen_kappa_score
cm0 = confusion_matrix(y_train, log_train_pred_60,labels=[1,0])
print('Confusion Matrix Train : \n', cm0)

cm1 = confusion_matrix(y_test, log_val_pred_60,labels=[1,0])
print('Confusion Matrix Test: \n', cm1)


KappaValue=cohen_kappa_score(y_test, log_val_pred_60)
print("Kappa Value :",KappaValue)
AUC=roc_auc_score(y_test, log_val_pred_60)

print("AUC         :",AUC)

##Random Forest
from sklearn.ensemble import RandomForestClassifier

rf=RandomForestClassifier(n_estimators=500,class_weight='balanced',random_state=101,max_depth=4)

rf.fit(X_train,y_train)

rf_probs=rf.predict_proba(X_test)
ns_probs = [0 for _ in range(len(y_test))]
ns_auc=roc_auc_score(y_test,ns_probs)
rf_probs=rf_probs[:,1]
rf_auc=roc_auc_score(y_test,rf_probs)
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('rf: ROC AUC=%.3f' % (rf_auc))
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)


pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(rf_fpr, rf_tpr, marker='.', label='RF')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()

fig = plt.figure(figsize=(12,8))

sns.distplot(rf_tpr,color='firebrick')

sns.distplot(rf_fpr,color='darkblue')
plt.title('TPR Vs FPR ')
plt.xlim([-.25, 1.2])

plt.text(0.1,4,'Negatives',color='darkblue')
plt.text(0.7,4,'Positives',color='firebrick')
plt.xlabel('Probability')
plt.ylabel('Distribution')
plt.show()

rf_train_pred_50=(rf.predict_proba(X_train)[:,1]>0.50).astype(bool)
rf_val_pred_50=(rf.predict_proba(X_test)[:,1]>0.50).astype(bool)
cm0 = confusion_matrix(y_train, rf_train_pred_50,labels=[1,0])
print('Confusion Matrix Train : \n', cm0)

cm1 = confusion_matrix(y_test, rf_val_pred_50,labels=[1,0])
print('Confusion Matrix Test: \n', cm1)


KappaValue=cohen_kappa_score(y_test, rf_val_pred_50)
print("Kappa Value :",KappaValue)
AUC=roc_auc_score(y_test, rf_val_pred_50)

print("AUC         :",AUC)

importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]
feat_labels=X.columns[1:]
for f in range(X_train.shape[1]):
    print("%2d) %-*s %f" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))

##XGB
clf = xgb.XGBClassifier(n_jobs=12, n_estimators=500)
clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)],
        eval_metric=["auc","error","logloss"],
        verbose=10)

plot_importance(clf,max_num_features=10)

xgb_probs=clf.predict_proba(X_test)
ns_probs = [0 for _ in range(len(y_test))]
ns_auc=roc_auc_score(y_test,ns_probs)
xgb_probs=xgb_probs[:,1]
xgb_auc=roc_auc_score(y_test,xgb_probs)
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('XGB: ROC AUC=%.3f' % (xgb_auc))
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_probs)

pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(xgb_fpr, xgb_tpr, marker='.', label='xgb')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()

fig = plt.figure(figsize=(12,8))

sns.distplot(xgb_tpr,color='firebrick')

sns.distplot(xgb_fpr,color='darkblue')
plt.title('TPR Vs FPR ')
plt.xlim([-.25, 1.2])

plt.text(0.1,4,'Negatives',color='darkblue')
plt.text(0.7,4,'Positives',color='firebrick')
plt.xlabel('Probability')
plt.ylabel('Distribution')
plt.show()

xgb_train_pred_50=(clf.predict_proba(X_train)[:,1]>0.50).astype(bool)
xgb_val_pred_50=(clf.predict_proba(X_test)[:,1]>0.50).astype(bool)
cm0 = confusion_matrix(y_train, xgb_train_pred_50,labels=[1,0])
print('Confusion Matrix Train : \n', cm0)

cm1 = confusion_matrix(y_test, xgb_val_pred_50,labels=[1,0])
print('Confusion Matrix Test: \n', cm1)


KappaValue=cohen_kappa_score(y_test, xgb_val_pred_50)
print("Kappa Value :",KappaValue)
AUC=roc_auc_score(y_test, xgb_val_pred_50)

print("AUC         :",AUC)